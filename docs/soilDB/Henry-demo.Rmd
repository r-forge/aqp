---
output:
  html_document:
    mathjax: null
    jquery: null
    smart: no
---

```{r setup, echo=FALSE, results='hide', warning=FALSE}
# setup
library(knitr, quietly=TRUE)
library(printr, quietly=TRUE)
opts_chunk$set(message=FALSE, warning=FALSE, background='#F7F7F7', fig.align='center', fig.retina=2, dev='png', tidy=FALSE, verbose=FALSE)
options(width=100, stringsAsFactors=FALSE)
```

Henry Mount Soil Climate Database Tutorial
==========================================
`r format(Sys.time(), "%Y-%m-%d")`
D.E. Beaudette


## Introduction
This document demonstrates how to use the [soilDB](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/soilDB/soilDB-Intro.html?root=aqp) package to download data from the Henry Mount soil climate database.


### Data Collection


### Current Work and Future Plans



## Setup R Environment
With a recent version of R (>= 2.15), it is possible to get all of the packages that this tutorial depends on via:
```{r install-deps, eval=FALSE}
# run these commands in the R console
install.packages('reshape', dep=TRUE) # stable version from CRAN + dependencies
install.packages('dismo', dep=TRUE) # stable version from CRAN + dependencies
install.packages('rgdal', dep=TRUE) # stable version from CRAN + dependencies
install.packages('soilDB', dep=TRUE) # stable version from CRAN + dependencies
install.packages('soilDB', repos="http://R-Forge.R-project.org", type='source') # most recent copy from r-forge
```


## Getting and Viewing Data
Data can be queried by:
 
 * project (typically a soil survey area, 'CA630')
 * NASIS user site ID (e.g. "2006CA7920001")

and optionally filtered by:

 * start date ("YYYY-MM-DD")
 * end date ("YYYY-MM-DD")
 * sensor type ("soiltemp" is the only type currently available)
 
and aggregated to the following granularity:

 * "day" (MAST and mean summer/winter temperatures are automatically computed)
 * "week"
 * "month"
 * "year"
 
```{r get-data, fig.width=6, fig.height=7, results='hide'}
library(soilDB)
library(lattice)

# get daily soil temperature data and summaries from Sequoia / Kings Canyon soil survey
x <- fetchHenry(project='CA792', gran = 'day')
```

Quick listing of site names, IDs, and coordinates
```{r view-data, fig.width=6, fig.height=7}
head(as.data.frame(x$sites)[, c('user_site_id', 'name', 'serial_number', 'MAST', 'Winter', 'Summer', 'functional.yrs', 'complete.yrs', 'dslv')])
```


### Plot Data
Note that there are gaps in the data: between site visits and lack of synchronization of site visits with start/end of the year.
```{r plot-time-series, fig.width=10, fig.height=7}
xyplot(sensor_value ~ date_time | id, data=x$soiltemp, type=c('l', 'g'), as.table=TRUE, layout=c(1,5), xlab='Date', ylab='Deg C')
```

```{r plot-time-series-levelplot, fig.width=10, fig.height=10}
# inspect data gaps
levelplot(factor(!is.na(sensor_value)) ~ doy * factor(year) | id, 
data=x$soiltemp, layout=c(1,5), col.regions=c('grey', 'RoyalBlue'), cuts=1, 
colorkey=FALSE, as.table=TRUE, scales=list(alternating=3), 
par.strip.text=list(cex=1), strip=strip.custom(bg='yellow'), 
xlab='Julian Day', ylab='Year')

# view data as levelplot
levelplot(sensor_value ~ doy * factor(year) | id, 
data=x$soiltemp, layout=c(1,5), col.regions = topo.colors(100),
colorkey=list(space='top'), as.table=TRUE, scales=list(alternating=3), 
par.strip.text=list(cex=1), strip=strip.custom(bg='grey'), 
xlab='Julian Day', ylab='Year')
```


## Data Summaries

In the presence of missing data, MAST calculations will be biased towards those data that are not missing. For example, a block of missing data in January will result in an estimated MAST that is too high due to the missing data from the middle of winter. It is possible to estimate (mostly) unbiased MAST values in the presence of some missing data by averaging multiple years of data by Julian day.  This approach will generate reasonable summaries in the presence of missing data, as long as data gaps are "covered" by corresponding data from another year. The longer the period of record and shorter the data gaps, the better.

When daily data are queried, unbiased summaries and indices of data "completeness" are calculated.
```{r data-summary, fig.width=6, fig.height=7}
as.data.frame(x$sites)[, c('user_site_id', 'name', 'MAST', 'Winter', 'Summer', 'functional.yrs', 'complete.yrs')]
```




### Additional Ideas

1. Save sites as shape file:
```{r save-as-shp, eval=FALSE}
library(rgdal)
writeOGR(x$sites, dsn='foldername', layer='filename', format='ESRI Shapefile')
```

2. Overlay site locations on a Google map

```{r map-data, eval=FALSE}
library(dismo)
g <- gmap(x$sites)
plot(g, interpolate=TRUE)
points(Mercator(x$sites), col='red')
```


----------------------------
This document is based on `aqp` version `r utils::packageDescription("aqp", field="Version")` and `soilDB` version `r utils::packageDescription("soilDB", field="Version")`.

